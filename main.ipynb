{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:45.986503900Z",
     "start_time": "2023-06-21T15:34:45.935546Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from scipy.optimize import minimize, least_squares\n",
    "from torch import float64\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "from linreg import Methods, LearningRateScheduling, LinearRegression\n",
    "\n",
    "\n",
    "def optimizer_handler(method, params, lr, beta_1=0.9, beta_2=0.999, factor=10):\n",
    "    match method:\n",
    "        case Methods.Classic:\n",
    "            return torch.optim.SGD(params, lr)\n",
    "        case Methods.Momentum:\n",
    "            return torch.optim.SGD(params, lr, beta_1)\n",
    "        case Methods.AdaGrad:\n",
    "            return torch.optim.Adagrad(params, lr * factor)\n",
    "        case Methods.RMSprop:\n",
    "            return torch.optim.RMSprop(params, lr, alpha=beta_2)\n",
    "        case Methods.Adam:\n",
    "            return torch.optim.Adam(params, lr, betas=(beta_1, beta_2))\n",
    "        case Methods.Nesterov:\n",
    "            return torch.optim.SGD(params, lr, nesterov=True, momentum=beta_1)\n",
    "\n",
    "\n",
    "def lr_scheduler_handler(optimizer, lrs, lr, epoch_size=30):\n",
    "    match lrs:\n",
    "        case LearningRateScheduling.Classic:\n",
    "            return torch.optim.lr_scheduler.LambdaLR(optimizer, lambda *_: 1)\n",
    "        case LearningRateScheduling.Stepwise:\n",
    "            return torch.optim.lr_scheduler.StepLR(optimizer, step_size=epoch_size, gamma=0.75)\n",
    "        case LearningRateScheduling.Exponential:\n",
    "            return torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "\n",
    "class TorchLinearRegression:\n",
    "    def __init__(self, T, X, Y, W=None):\n",
    "        self.T_funcs = T\n",
    "        self.T = torch.tensor([T[i % len(T)](X[i // len(T)]) for i in range(len(T) * len(X))], dtype=float64).reshape(\n",
    "            len(X), len(T))\n",
    "        self.X = torch.tensor(X, dtype=float64)\n",
    "        self.Y = torch.tensor(Y, dtype=float64)\n",
    "        self.loss_f = nn.MSELoss(reduction='mean')\n",
    "\n",
    "        self.refresh(W)\n",
    "\n",
    "    def optimize(self, method=Methods.Classic, lr=0.01, lrs=LearningRateScheduling.Classic, max_steps=1500):\n",
    "        optimizer = optimizer_handler(method, [self.W], lr)\n",
    "        scheduler = lr_scheduler_handler(optimizer, lrs, lr=lr)\n",
    "\n",
    "        for i in range(max_steps):\n",
    "            optimizer.zero_grad()\n",
    "            self.loss(self.W, is_no_grad=False)\n",
    "            optimizer.step()\n",
    "            self.W_points.append(self.W.clone().detach().numpy())\n",
    "            scheduler.step()\n",
    "\n",
    "        return self.W\n",
    "\n",
    "    def loss(self, W, is_no_grad=True):\n",
    "        if isinstance(W, np.ndarray):\n",
    "            W = np.array(W).reshape(len(self.T_funcs), 1)\n",
    "            W = Variable(torch.tensor(W, dtype=float64), requires_grad=True)\n",
    "        if is_no_grad:\n",
    "            with torch.no_grad():\n",
    "                loss_val = self.loss_f(self.T @ W, self.Y)\n",
    "                return float(loss_val) * len(self.X)\n",
    "        else:\n",
    "            loss_val = self.loss_f(self.T @ W, self.Y)\n",
    "            loss_val.backward()\n",
    "            return float(loss_val)\n",
    "\n",
    "    def refresh(self, W=None):\n",
    "        if isinstance(W, np.ndarray):\n",
    "            W = np.array(W, dtype=float64).reshape(len(self.T_funcs), 1)\n",
    "        if W is None:\n",
    "            W = torch.randn(len(self.T_funcs), 1, dtype=float64)\n",
    "        self.W = Variable(torch.tensor(W), requires_grad=True)\n",
    "        self.W_points = [torch.clone(self.W).detach().numpy()]\n",
    "\n",
    "    def analytical_solution(self):\n",
    "        return (torch.linalg.inv(torch.t(self.T) @ self.T) @ torch.t(self.T)) @ self.Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:45.986503900Z",
     "start_time": "2023-06-21T15:34:45.955250200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "from time import time\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, result, mem, time, other=None):\n",
    "        if other is None:\n",
    "            other = []\n",
    "        self.result = result\n",
    "        self.mem = mem\n",
    "        self.time = time\n",
    "        self.other = other\n",
    "\n",
    "\n",
    "def get_metrics(func):\n",
    "    start = time()\n",
    "    tracemalloc.start()\n",
    "    result = func()\n",
    "    mem = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    end = time()\n",
    "\n",
    "    return Metrics(result, mem[1] - mem[0], end - start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.002493Z",
     "start_time": "2023-06-21T15:34:45.986503900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "from excel import ExcellSaver\n",
    "\n",
    "excel_saver = ExcellSaver()\n",
    "\n",
    "\n",
    "def add_metrics_row(metrics):\n",
    "    global excel_saver\n",
    "\n",
    "    row = []\n",
    "    for pair in metrics.other:\n",
    "        row.append(pair[1])\n",
    "    row.append(metrics.time)\n",
    "    row.append(metrics.mem)\n",
    "\n",
    "    excel_saver.add_row(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.017749800Z",
     "start_time": "2023-06-21T15:34:46.002493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "from linreg import gen_linear_reg, visualise_approximation, sgd_handler\n",
    "\n",
    "Output = Enum(\"Output\", [\"No\", \"Console\", \"Excel\"])\n",
    "\n",
    "\n",
    "def visualise(f, points, title, x_label=\"x\", y_label=\"y\"):\n",
    "    values = np.transpose(np.array(points))\n",
    "    X = np.linspace(min(values[0]) - 10, max(values[0]) + 10, 100)\n",
    "    Y = np.linspace(min(values[1]) - 10, max(values[1]) + 10, 100)\n",
    "    Z = [[f(np.array([X[i], Y[j]])) for i in range(len(X))] for j in range(len(Y))]\n",
    "    plt.contour(X, Y, Z, 80)\n",
    "\n",
    "    plt.plot(values[0], values[1], marker='.')\n",
    "    plt.plot(values[0][0], values[1][0], 'og')\n",
    "    plt.plot(values[0][-1], values[1][-1], 'or')\n",
    "    plt.title(title)\n",
    "    plt.legend(['Route', 'Start point', 'End point'])\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_abs_rel_errors_info(metrics, excepted, received):\n",
    "    absolute_error = np.linalg.norm(excepted - received)\n",
    "    relative_error = absolute_error / np.linalg.norm(excepted)\n",
    "\n",
    "    metrics.other.append([\"Absolute Error\", str(absolute_error)])\n",
    "    metrics.other.append([\"Relative Error\", str(relative_error)])\n",
    "\n",
    "\n",
    "def add_linreg_errors_info(metrics, linreg):\n",
    "    expected_linreg_loss = linreg.loss(linreg.analytical_solution())\n",
    "    linreg_loss = linreg.loss(linreg.W)\n",
    "    metrics.other.append([\"Expected Loss\", expected_linreg_loss])\n",
    "    metrics.other.append([\"Actual Loss\", linreg_loss])\n",
    "\n",
    "\n",
    "def test_sgd_variants(output=Output.No):\n",
    "    global excel_saver\n",
    "\n",
    "    if output == Output.Excel:\n",
    "        excel_saver.add_new_sheet([\"Whose\", \"Method\", \"Expected Loss\", \"Actual Loss\", \"Time\", \"Memory\"],\n",
    "                                  \"Test SGD Methods\")\n",
    "\n",
    "    count_2_arity = 1\n",
    "    count_other_arity = 0\n",
    "    left_coeffs_border = -2.\n",
    "    right_coeffs_border = 2.\n",
    "    left_x_border = -2.\n",
    "    right_x_border = 2.\n",
    "    deviation = 3.\n",
    "\n",
    "    for i in range(count_2_arity + count_other_arity):\n",
    "        arity = 2 if i < count_2_arity else random.randint(3, 8)\n",
    "        num_train_points = random.randint(50, 100)\n",
    "        start_point = np.array([float(random.randint(15, 30)) for i in range(arity)])\n",
    "        linreg = gen_linear_reg(\n",
    "            arity - 1, num_train_points,\n",
    "            left_coeffs_border, right_coeffs_border,\n",
    "            left_x_border, right_x_border,\n",
    "            deviation\n",
    "        )\n",
    "        torch_linreg = TorchLinearRegression(linreg.T_funcs, linreg.X, linreg.Y, torch.tensor(start_point))\n",
    "        self_scheduled = (Methods.AdaGrad, Methods.Adam, Methods.RMSprop)\n",
    "\n",
    "        for method in Methods:\n",
    "            lr = 0.01\n",
    "            if method in self_scheduled:\n",
    "                lr = 0.1\n",
    "                linreg.refresh(start_point)\n",
    "                our_metrics = get_metrics(lambda: sgd_handler(linreg, lambda *_: lr, method, store_points=True))\n",
    "                title = 'Our ' + method.name\n",
    "                if len(linreg.T_funcs) == 2:\n",
    "                    visualise(linreg.loss, linreg.W_points, title)\n",
    "                visualise_approximation(linreg, title)\n",
    "\n",
    "                title = 'Torch ' + method.name\n",
    "                torch_linreg.refresh(torch.tensor(start_point))\n",
    "                torch_metrics = get_metrics(lambda: torch_linreg.optimize(method, lr=lr))\n",
    "                if len(torch_linreg.T_funcs) == 2:\n",
    "                    visualise(torch_linreg.loss, torch_linreg.W_points, title)\n",
    "                visualise_approximation(torch_linreg, title)\n",
    "\n",
    "                match output:\n",
    "                    case Output.Excel:\n",
    "                        our_metrics.other.append([\"Whose\", \"Our\"])\n",
    "                        our_metrics.other.append([\"Method\", method.name.replace(\"Methods.\", \"\")])\n",
    "                        add_linreg_errors_info(our_metrics, linreg)\n",
    "                        add_metrics_row(our_metrics)\n",
    "\n",
    "                        torch_metrics.other.append([\"Whose\", \"Torch\"])\n",
    "                        torch_metrics.other.append([\"Method\", method.name.replace(\"Methods.\", \"\")])\n",
    "                        add_linreg_errors_info(torch_metrics, torch_linreg)\n",
    "                        add_metrics_row(torch_metrics)\n",
    "                    case Output.Console:\n",
    "                        pass\n",
    "\n",
    "# test_sgd_variants(Output.Excel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.049741500Z",
     "start_time": "2023-06-21T15:34:46.030780800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "def derivative(f, x, i, delt=0.0001):\n",
    "    x_1 = np.copy(x)\n",
    "    x_2 = np.copy(x)\n",
    "    x_1[i] += delt\n",
    "    x_2[i] -= delt\n",
    "    y_1 = f(x_1)\n",
    "    y_2 = f(x_2)\n",
    "    return (y_1 - y_2) / (2 * delt)\n",
    "\n",
    "\n",
    "def grad(f, delt=0.01):\n",
    "    def grad_calc(x):\n",
    "        array = []\n",
    "        for i in range(len(x)):\n",
    "            array.append(derivative(f, x, i, delt))\n",
    "        return np.array(array)\n",
    "\n",
    "    return grad_calc\n",
    "\n",
    "\n",
    "def hessian(f):\n",
    "    def calc(x):\n",
    "        B = np.asarray([[0. for _ in range(len(x))] for _ in range(len(x))])\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                B[i][j] = derivative(lambda x_tmp: derivative(f, x_tmp, j), x, i)\n",
    "        return B\n",
    "\n",
    "    return calc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.070568100Z",
     "start_time": "2023-06-21T15:34:46.054912900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "Algorithms = Enum('Algorithms', ['Newton', 'DogLeg', 'BFGS', 'LBFGS'])\n",
    "\n",
    "\n",
    "def optimize_handler(fun, x0, algorithm=Algorithms.Newton):\n",
    "    match algorithm:\n",
    "        case Algorithms.Newton:\n",
    "            return least_squares(fun, x0)\n",
    "        case Algorithms.DogLeg:\n",
    "            return minimize(fun, x0, method='dogleg', jac=grad(fun), hess=hessian(fun))\n",
    "        case Algorithms.BFGS:\n",
    "            return minimize(fun, x0, method='BFGS')\n",
    "        case Algorithms.LBFGS:\n",
    "            return minimize(fun, x0, method='L-BFGS-B')\n",
    "\n",
    "\n",
    "def our_optimize_handler(fun, x0, algorithm=Algorithms.Newton):\n",
    "    match algorithm:\n",
    "        case Algorithms.Newton:\n",
    "            return gauss_newton(x0, fun)\n",
    "        case Algorithms.DogLeg:\n",
    "            return dogleg(fun, x0)\n",
    "        case Algorithms.BFGS:\n",
    "            return bfgs(fun, x0)\n",
    "        case Algorithms.LBFGS:\n",
    "            return lbfgs(fun, x0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.086183Z",
     "start_time": "2023-06-21T15:34:46.070568100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "#gen random excepted coeffs\n",
    "def gen_excepted(lb=-10, rb=10, min_size=2, max_size=10):\n",
    "    return np.random.uniform(lb, rb, size=(np.random.randint(min_size, max_size)))\n",
    "\n",
    "\n",
    "#gen parameters with poly functions of points\n",
    "def gen_parameters(excepted, N=100, deviation=0.01, is_random_N=False, lb_N=50, rb_N=200):\n",
    "    M = len(excepted)\n",
    "    if is_random_N:\n",
    "        N = np.random.randint(lb_N, rb_N)\n",
    "\n",
    "    noise = torch.randn(N, 1, dtype=float64) * deviation\n",
    "    powers = [(M - 1 - i) for i in range(M)]\n",
    "    Funcs = np.array([lambda x, i=i: (x ** powers[i]) for i in range(M)])\n",
    "    X = torch.randn(N, 1, dtype=float64)\n",
    "    Y = sum([float(excepted[i]) * Funcs[i](X) for i in range(M)]) + noise\n",
    "    T = torch.zeros(len(X), len(Funcs), dtype=float64)\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(Funcs)):\n",
    "            T.data[i, j] = Funcs[j](X.data[i])\n",
    "\n",
    "    return (X, Y, T, Funcs)\n",
    "\n",
    "\n",
    "#gen least squares loss function\n",
    "def gen_f(X, Y, T, Funcs):\n",
    "    def f(W):\n",
    "        W1 = None\n",
    "        if isinstance(W, torch.Tensor):\n",
    "            W1 = W\n",
    "        else:\n",
    "            W1 = np.copy(W).reshape(len(Funcs), 1)\n",
    "            W1 = torch.tensor(W1, dtype=float64)\n",
    "        model = T.mm(W1)\n",
    "        mse = nn.MSELoss()\n",
    "        res = mse(model, Y)\n",
    "        return res if isinstance(W, torch.Tensor) else res.item()\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "#gen random x0\n",
    "def gen_x0(len, lb=-20, rb=20):\n",
    "    return np.random.uniform(lb, rb, size=len)\n",
    "\n",
    "\n",
    "#numeric grad for any function\n",
    "def num_grad(f, delt=0.01):\n",
    "    return grad(f, delt=delt)\n",
    "\n",
    "\n",
    "#analityc grad for any linear function of weights with the least squares problem\n",
    "def an_grad(X, Y, T, Funcs):\n",
    "    M = len(Funcs)\n",
    "\n",
    "    def an_grad_calc(W):\n",
    "        array = []\n",
    "        components_value = ((T @ torch.tensor(W, dtype=float64).reshape(len(W), 1)) - Y)\n",
    "        for i in range(M):\n",
    "            x_fi = Funcs[i](X)\n",
    "            array.append((x_fi.T @ components_value).item())\n",
    "        return np.array(array)\n",
    "\n",
    "    return an_grad_calc\n",
    "\n",
    "\n",
    "#torch grad for any function with the least squares problem\n",
    "def torch_grad(f):\n",
    "    def torch_grad_calc(W):\n",
    "        x = torch.tensor(W, dtype=float64, requires_grad=True).reshape(len(W), 1)\n",
    "        x.retain_grad()\n",
    "        Q = f(x)\n",
    "        Q.backward()\n",
    "        return x.grad.T.detach().numpy().reshape(len(W))\n",
    "\n",
    "    return torch_grad_calc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.101804900Z",
     "start_time": "2023-06-21T15:34:46.086183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "from trustreg import gauss_newton, dogleg, bfgs, lbfgs\n",
    "\n",
    "\n",
    "def test_scipy_methods(output: Output.No):\n",
    "    global excel_saver\n",
    "\n",
    "    if output == Output.Excel:\n",
    "        excel_saver.add_new_sheet([\"Whose\", \"Algorithm\", \"Absolute Error\", \"Relative Error\", \"Time\", \"Memory\"])\n",
    "\n",
    "    count_examples = 1\n",
    "    for _ in range(count_examples):\n",
    "        expected = gen_excepted(max_size=6)\n",
    "        X, Y, T, Funcs = gen_parameters(expected, is_random_N=True, deviation=6)\n",
    "        f = gen_f(X, Y, T, Funcs)\n",
    "        x0 = gen_x0(len(Funcs))\n",
    "\n",
    "        def tmp(i):\n",
    "            def culc(W):\n",
    "                return (torch.tensor(W) @ torch.t(T[i]) - Y[i]).item()\n",
    "\n",
    "            return culc\n",
    "\n",
    "        for algorithm in Algorithms:\n",
    "            scipy_metrics = get_metrics(lambda: optimize_handler(f, x0, algorithm))\n",
    "            our_metrics = None\n",
    "            if algorithm == Algorithms.Newton:\n",
    "                funcs = [tmp(i) for i in range(len(X))]\n",
    "                our_metrics = get_metrics(lambda: our_optimize_handler(funcs, x0, algorithm))\n",
    "            else:\n",
    "                our_metrics = get_metrics(lambda: our_optimize_handler(f, x0, algorithm))\n",
    "\n",
    "            linreg = LinearRegression(Funcs, our_metrics.result, X.detach().numpy(), Y.detach().numpy())\n",
    "            scipy_linreg = LinearRegression(Funcs, scipy_metrics.result.x, X.detach().numpy(), Y.detach().numpy())\n",
    "\n",
    "            visualise_approximation(linreg, f\"Our {algorithm.name.replace('Algorithms', '')}\")\n",
    "            visualise_approximation(scipy_linreg, f\"SciPy {algorithm.name.replace('Algorithms', '')}\")\n",
    "\n",
    "            match output:\n",
    "                case Output.Excel:\n",
    "                    our_metrics.other.append([\"Whose\", \"Our\"])\n",
    "                    our_metrics.other.append([\"Algorithm\", algorithm.name.replace(\"Algorithm.\", \"\")])\n",
    "                    add_abs_rel_errors_info(our_metrics, expected, our_metrics.result)\n",
    "                    add_metrics_row(our_metrics)\n",
    "\n",
    "                    scipy_metrics.other.append([\"Whose\", \"SciPy\"])\n",
    "                    scipy_metrics.other.append([\"Algorithm\", algorithm.name.replace(\"Algorithm.\", \"\")])\n",
    "                    add_abs_rel_errors_info(scipy_metrics, expected, scipy_metrics.result.x)\n",
    "                    add_metrics_row(scipy_metrics)\n",
    "\n",
    "# test_scipy_methods(Output.Excel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.117419500Z",
     "start_time": "2023-06-21T15:34:46.101804900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def test_pytorch_grad_calc(output=Output.No):\n",
    "    global excel_saver\n",
    "\n",
    "    if output == Output.Excel:\n",
    "        excel_saver.add_new_sheet([\"Method Grad Calc\", \"Absolute Error\", \"Relative Error\", \"Time\", \"Memory\"],\n",
    "                                  \"Pytorch Gradient Calculation\")\n",
    "\n",
    "    count_examples = 50\n",
    "    for _ in range(count_examples):\n",
    "        expected = gen_excepted()\n",
    "        X, Y, T, Funcs = gen_parameters(expected, is_random_N=True, deviation=6)\n",
    "        f = gen_f(X, Y, T, Funcs)\n",
    "        x0 = gen_x0(len(Funcs))\n",
    "        num_grad_f = num_grad(f)\n",
    "        an_grad_f = an_grad(X, Y, T, Funcs)\n",
    "        torch_grad_f = torch_grad(f)\n",
    "\n",
    "        num_metrics = get_metrics(lambda: minimize(f, x0, method='CG', jac=num_grad_f).x)\n",
    "        an_metrics = get_metrics(lambda: minimize(f, x0, method='CG', jac=an_grad_f).x)\n",
    "        torch_metrics = get_metrics(lambda: minimize(f, x0, method='CG', jac=torch_grad_f).x)\n",
    "\n",
    "        match output:\n",
    "            case Output.Excel:\n",
    "                num_metrics.other.append([\"Method Grad Calc\", \"Numerical\"])\n",
    "                add_abs_rel_errors_info(num_metrics, expected, num_metrics.result)\n",
    "                add_metrics_row(num_metrics)\n",
    "\n",
    "                an_metrics.other.append([\"Method Grad Calc\", \"Analytic\"])\n",
    "                add_abs_rel_errors_info(an_metrics, expected, an_metrics.result)\n",
    "                add_metrics_row(an_metrics)\n",
    "\n",
    "                torch_metrics.other.append([\"Method Grad Calc\", \"PyTorch\"])\n",
    "                add_abs_rel_errors_info(torch_metrics, expected, torch_metrics.result)\n",
    "                add_metrics_row(torch_metrics)\n",
    "\n",
    "# test_pytorch_grad_calc(Output.Excel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.133051300Z",
     "start_time": "2023-06-21T15:34:46.117419500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "BoundMethods = Enum('BoundMethods', ['L-BFGS-B', 'Nelder-Mead', 'trust-constr'])\n",
    "\n",
    "\n",
    "def gen_bounds(arity, left_bound=-20, right_bound=20, delta_between=3):\n",
    "    bounds = []\n",
    "    for _ in range(arity):\n",
    "        min_val = random.randint(left_bound, right_bound)\n",
    "        max_val = random.randint(min_val + delta_between, right_bound + delta_between)\n",
    "        bounds.append([min_val, max_val])\n",
    "\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def gen_start_point_by_bounds(bounds):\n",
    "    x0 = []\n",
    "\n",
    "    for i in range(len(bounds)):\n",
    "        x0.append(random.uniform(bounds[i][0], bounds[i][1]))\n",
    "\n",
    "    return np.array(x0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:46.148695300Z",
     "start_time": "2023-06-21T15:34:46.133051300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "\n",
    "\n",
    "def test_scipy_bounds(output=Output.No):\n",
    "    global excel_saver\n",
    "\n",
    "    if output == Output.Excel:\n",
    "        excel_saver.add_new_sheet([\"Mode\", \"Method\", \"Bounds\", \"Absolute Error\", \"Relative Error\", \"Time\", \"Memory\"], \"SciPy Bounds\")\n",
    "\n",
    "    count_examples = 3\n",
    "\n",
    "    for _ in range(count_examples):\n",
    "        expected = gen_excepted()\n",
    "        X, Y, T, Funcs = gen_parameters(expected, is_random_N=True)\n",
    "        f = gen_f(X, Y, T, Funcs)\n",
    "        x0 = gen_x0(len(Funcs))\n",
    "        bounds = gen_bounds(len(Funcs))\n",
    "\n",
    "        for method in BoundMethods:\n",
    "            x0 = gen_start_point_by_bounds(bounds)\n",
    "            metrics = get_metrics(lambda *_: minimize(f, x0, method=method.name.replace(\"BoundMethods.\", \"\")).x)\n",
    "            bound_metrics = get_metrics(lambda *_: minimize(f, x0, method=method.name.replace(\"BoundMethods.\", \"\"), bounds=bounds).x)\n",
    "\n",
    "            match output:\n",
    "                case Output.Excel:\n",
    "                    metrics.other.append([\"Mode\", \"No Bounds\"])\n",
    "                    metrics.other.append([\"Method\", method.name.replace(\"BoundMethods.\", \"\")])\n",
    "                    metrics.other.append([\"Bounds\", \"\"])\n",
    "                    add_abs_rel_errors_info(metrics, expected, metrics.result)\n",
    "                    add_metrics_row(metrics)\n",
    "\n",
    "                    bound_metrics.other.append([\"Mode\", \"Bounds\"])\n",
    "                    bound_metrics.other.append([\"Method\", method.name.replace(\"BoundMethods.\", \"\")])\n",
    "                    bound_metrics.other.append([\"Bounds\", \"\\r\\n\".join(\n",
    "                        [f\"{bounds[i][0]} <= x{i + 1} <= {bounds[i][1]}\" for i in range(len(bounds))])])\n",
    "                    add_abs_rel_errors_info(bound_metrics, expected, bound_metrics.result)\n",
    "                    add_metrics_row(bound_metrics)\n",
    "\n",
    "\n",
    "test_scipy_bounds(Output.Excel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:51.507791400Z",
     "start_time": "2023-06-21T15:34:46.148695300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "excel_saver.create_excel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:34:51.554189Z",
     "start_time": "2023-06-21T15:34:51.513665100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
